         Description
           Why HCA?
         At its founding in 1968, Nashville-based HCA was one of the nation's first hospital companies. Today, one of the nation's leading providers of healthcare services, HCA is comprised of locally-managed facilities that include more than 250 hospitals and freestanding surgery centers in 20 states and the United Kingdom, employing approximately 230,000 people. Approximately four to five percent of all inpatient care delivered in the country today is provided by HCA facilities resulting in more than 26M patient encounters each year. HCA is committed to the care and improvement of human life and strives to deliver high quality, cost effective healthcare in the communities we serve. Building on the foundation provided by our Mission & Values, HCA puts patients first and works to constantly improve the care we provide by implementing measures that support our caregivers, help ensure patient safety and provide the highest possible quality.
          Additional Facts:
         • Ranked 63 in Fortune 500
         • Competitive Fortune 100, industry matched salaries and yearly merit increase
         • Computerworld Top 50 Best Places to Work in IT since 2009
         • Named one of the “World’s Most Ethical Companies” since 2010
         • 106 HCA hospitals are on The Joint Commission’s list of top performers on key quality measures
           JOB SUMMARY:
         This role will provide application development for specific business environments. Focus on setting technical direction on groups of applications and similar technologies as well as taking responsibility for technically robust solutions encompassing all business, architecture, and technology constraints.
          Responsible for building and supporting a Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
          Manage and optimize Hadoop/Spark clusters, which may include many large HBase instances
          Support regular requests to move data from one cluster to another
          Manage production support teams to make sure service levels are maintained and any interruption is resolved in a timely fashion
          Bring new data sources into HDFS, transform and load to databases.
          Work collaboratively with Data Scientists and business and IT leaders throughout the company to understand Big Data needs and use cases.
         Qualifications:
           QUALIFICATIONS:
          Strong understanding of best practices and standards for Hadoop application design and implementation.
          Hands-on experience with Cloudera Distributed Hadoop (CDH) and experience with many of the following components:
            Hadoop, MapReduce, Spark Streaming, Impala, Hive, Solr, YARN
            Java, Python, or Scala
            SQL, JSON, XML
            RegEx
            Sqoop
            Avro, Parquet
            Flume, Kafka
          Experience in developing MapReduce programs using Apache Hadoop for working with Big Data.
          Experience having deployed Big Data Technologies to Production.
          Understanding of Lambda Design Architectures and Real-Time Streaming
          Ability to multitask and to balance competing priorities.
          Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
          Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
          Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.
          Preferred
         A successful candidate may have:
          Experience in Healthcare Domain
          Experience in Patient Data
          Hardware/Operating Systems:
          Linux
          UNIX
          Distributed, highly-scalable processing environments
          Networking - basic understanding of networking with respect to distributed server and file systems connectivity and troubleshooting of connectivity errors
          Databases
         :
          RDBMS – Teradata
          Other Languages – Java, Python, Scala, R
          Build Systems – Maven, Ant
          Source Control Systems – Git, Mercurial
          Continuous Integration Systems – Jenkins or Bamboo
          Config/Orchestration – Zookeeper, Puppet, Salt, Ansible, Chef, Oozie, Pig
          Certifications (a plus, but not required):
           CCDH (Cloudera Certified Developer for Apache Hadoop)