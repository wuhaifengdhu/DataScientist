        In the financial world, time is money. We are the fastest provider of market data, financial news and electronic trades in an industry where every second counts. We, the Network Infrastructure team, develop systems that manage the distribution of data across our network for various products. Our key focus when building our high-quality distribution algorithms is the real-time monitoring of changing market conditions, loads on distribution servers and network outages.
        As a data scientist on our team, you will analyze the efficiency of distribution algorithms and suggest innovative features and enhancements to improve their quality. You will have a unique opportunity to work with product and engineering teams across the company and devise customized solutions based on their unique needs. You'll play a key role on the Network Infrastructure team and you will also be part of larger Data Science and Machine Learning community where you can share your valuable experiences and ideas. Right now, we are using Python and Spark to process data from various datastores such as MS-SQL, HDFS, Cassandra, and Splunk. We are also looking to enrich our analytical stack with data visualization tools, predictive tools for building simulations, and powerful exploratory data tools for identifying patterns.
        We'll trust you to:
        * Partner with various product and engineering teams across the company
        * Be self-motivated and thrive in a fast-paced and collaborative environment
        * Take full ownership of the full software development life-cycle, including researching infrastructure needs for adopting new technologies
        You need to have:
        * Proven experience programming in Python/R/SAS/Matlab or similar technology
        * Knowledge of data science and machine learning methodologies
        * Background in statistical inference over time-series, unsupervised data in a professional environment
        * Knowledge of querying relational databases (MSSQL, Oracle, MySQL) or NoSQL (Cassandra/MongoDB)
        * Experience with distributed datastores (Hadoop/S3) or search technologies (Splunk/Solr)
        * Self-driven attitude to find new opportunities to increase system performance
        We'd love to see:
        * Knowledge of data visualization tools such as Tableau/QlikView or statistical GoogleCharts/D3.JS
        * Familiarity with Spark Batch & Streaming
        * Strong communication skills and a collaborative attitude
        #dj
        All qualified candidates are encouraged to apply by submitting their resume as an MS word document including a cover letter with a summary of relevant qualifications, highlighting clearly any special or relevant experience.