        At Netflix, we don't just deal with huge scale, we deal with a huge diversity of scale. We run thousands of applications on our back-end cloud systems. We serve hundreds of thousands of TV shows and movies to millions of customers across millions of devices, distributed across thousands of device families, all of which are constantly evolving and changing.
        The Real-Time Analytics group at Netflix builds systems which continuously use diverse telemetry sources within our environment to sift through millions of signals and arrive at actionable, high-confidence decisions about what's going on in our environment, and what we should do about it. Some work we've already talked about publicly (and would like to open-source) includes:
        1. Noticing when one out of thousands of servers is misbehaving based on Outlier Detection and automatically replacing it with a new server;
        2. Automatically detecting whether new code deployed to production is at least as performant and correct as baseline code, and either accelerating deployment globally or rolling it back
        3. Automatically monitoring for health of applications, and alerting users when the application skews from normal behavior. For more details, take a look at our talk at AWS re:Invent.
        We see huge opportunities for using RTA decisions to drive automated systems, both to improve our ecosystem's self-healing capabilities, but also to make it easier for engineers to understand what's most important for them to look at, automatically deduce correlation and causation, and notice the most minute, imperceptible changes in our streaming environment before our customers do.
        Our analytics engineers build models that take advanced statistical analysis approaches and machine learning techniques to provide recommendations or, in many cases, make decisive automated action in managing the production environment. If extracting meaning out of a whole lot of data (AKA noise) is fascinating to you, we should talk. If you like deducing and understanding control system patterns, we should definitely talk.
        What You'll Be DoingYou'll work closely with operations engineers and application developers to translate infrastructure monitoring problems into intelligent algorithmsYou'll learn, develop, and apply new techniques in the intersection of computer science, statistics and mathYou'll create anomaly detection models on top of large scale, multidimensional, real-time streaming and batch infrastructure dataYou'll bring scientific rigor, and a bias to action in solving problemsYou'll be automating your work by partnering with platform engineers to design a machine learning platform to accelerate model development and productizationWhat You'll BringYou're a great communicator, and can explain complicated mathematical concepts to software engineersYou've got prior academic and industry experience with statistical modeling and machine learning techniquesYou've worked with statistical analysis tools like R and PythonYou've got experience with time-series analysis techniques, including forecasting methodologiesYou've worked with machine generated telemetry (system and application metrics)You've deployed, maintained and performance tuned machine learning models in a production environmentAdded BonusExperience writing enterprise grade Java, Scala, or Python codeExperience with data stream mining techniquesDigital Signal Processing (DSP) knowledge