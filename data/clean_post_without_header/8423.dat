        Sabre is the global leader in innovative technology that leads the travel industry. We are always looking for bright and driven people who have a penchant for technology and want to hone their skills. If you are interested in challenging work, being part of a global team, and solving complex problems through technology, business intelligence and analytics, and Agile practices - then Sabre is right for you! It is our people who develop and deliver powerful solutions that meet the current and future needs for our airline, hotel, and travel agency customers.
        GENERAL DESCRIPTION:
        Work Environment: Enterprise Data & Analytics
        The successful candidate will work in an Enterprise Data and Analytics (EDA) group as part of a platform team. This team works with the latest Data and Analytics technologies like Hadoop, Tableau, Teradata, Oracle, Vertica, AWS Cloud native services and others. The team is responsible to build and manage the platform for business units and customers, solution architecture, building tools, components and services. This platform also supports self service capabilities to both technical and business users i.e. developers, analysts and data science. Platform, data and services must be of high quality and reliability in batch and near real time modes. The platform infrastructure is a hybrid model on premise and AWS cloud.
        The ideal candidate must enjoy being in a lead role but be able to maintain their own individual work. Strong individual contributor and team player! You need to have a strong background in AWS.
        Duties
        * Responsible for implementation and ongoing administration of Hadoop infrastructure.
        * Work with the Dev teams to optimize cluster usage and ensure timely execution of business-critical workloads
        * Develops and maintains documentation of cloud environments, integration platforms, data flow map, server inventories, network design diagram, entity-relationship diagram, process workflows.
        * Design cloud solutions based on business and solution requirements as well as legal, security/privacy and firm policy constraints.
        * Lead system performance benchmarking and establish standards and best practices to support high-performing computing environments.
        * Recommends development team tools, processes, and deliverables. Recommends/Implements process improvement.
        * Applies agile development methodologies to highly complex modules.
        * Provides ongoing direction/design of application suite/architecture, and data architecture.
        * Identifies connectivity and interface requirements to support integration efforts across hybrid cloud environment for production as well as non-production environments.
        * Work cross-functionally to understand the linkage between business goals, business architectures, and technology architectures â€“ and strive to further business goals via organic or inorganic evolution of cloud architectures.
        EDUCATION Bachelor's degree or equivalent, Master's degree preferred.
        EXPERIENCE
        Minimum 8 years related experience. Advanced computer software skills. Excellent written and verbal communication skills; ability to lead and direct multiple projects simultaneously; ability to delegate work to subordinate or less experienced team members; proven leadership ability.
        Background: Required
        * BA/BS degree or equivalent experience; Engineering or Math background preferred
        * 5 years of Data architecture, Data Integration, Data warehousing, and Big Data
        * 3 years of Hadoop Administration, DevOps and Support
        * AWS Certified Architect with experience of building data platform on AWS
        * Experience in data and analytics development platform and systems
        * AWS certified Architect with hands on AWS cloud services (EC2, S3, Redshift, VPC, VPN etc.)
        * Hands on experience of implementation security on Big Data Platform and Cloud with active directory or LDAP integration.
        Background: Preferred
        * AWS Solution Architect or Professional Certification.
        * Experience managing Petabyte scale Hadoop cluster
        * Experience with Chef, Puppet, or Ansible in production environments with many nodes.
        * Hands on experience provisioning/building clusters using with Terraform, Cloud Formation and JSON.
        * Strong scripting skills, i.e., Python, Bash, Ruby, Perl, etc.
        * Knowledge of IP networking, VPC, VPN's, DNS, load balancing and fire-walling.
        * Familiarity with any monitoring tools like Nagios, CheckMK, Graphite, AppDynamics, NewRelic etc.
        * Experience with revision control source code repositories (Git, SVN).
        * Management of continuous integration servers like Jenkins, Bamboo and TeamCity.
        * Understanding and experience with code deployment (tagging).
        * Experience with integrating Big Data RBAC, Sentry, Knox, Ranger, Atlas and IAM role with AD or LDAP
        At Sabre, we are fortunate to have the resources of a large company paired with the culture of a startup. Our company culture includes casual work environments, employee amenities, flexible work arrangements, and exceptional learning opportunities. And, you will be surrounded by intelligent team members who you will be proud to call your peers. To learn more about the people and culture at Sabre, follow us on Twitter, Facebook and LinkedIn. Sabre is an equal employment opportunity/affirmative action employer and is committed to providing equal employment opportunities to minorities, females, veterans, and disabled individuals.