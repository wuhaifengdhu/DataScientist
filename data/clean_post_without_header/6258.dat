        Monsanto's mission is centered on developingagricultural solutions for a sustainable future that will include a globalpopulation projected to eclipse 9.6 billion by 2050. We approach agricultureholistically, looking across a broad range of solutions from using biotechnologyand plant breeding to produce the best possible seeds, to advanced predictiveand prescriptive analytics designed to select the best possible crop system forevery acre.
        To make this possible, Monsanto collects terabytesof data across all aspects of its operations, from genome sequencing, cropfield trials, manufacturing, supply chain, and everything in between. There isan enormous need and potential here to do something that has never been donebefore. We need great Big Data Engineers to help transform these complex scientificdatasets into innovative software that is deployed across the pipeline,accelerating the pace and quality of all crop system development decisions tounbelievable levels.
        What you will do:
        * Be a critical senior member of a full-stack data engineering team focused on creating distributed analysis capabilities around our scientific datasets
        * Think through complex scientific problems and work to solve them by applying cutting edge data engineering practices
        * Collaborate closely with your engineering team colleagues and with data scientists across multiple research teams
        * Take pride in software craftsmanship, diving deep into code and constantly innovating
        Why you should join us:
        * Work with other top level talent solving a wide range of complex and unique challenges that have real world impact
        * We value the exploration of all relevant technology stacks in order to find the best fit for each dataset
        * We prioritize and pursue opportunities to present our work at relevant technical conferences: https://youtu.be/6KEvLURBenM
        * Our environment values your talent over a role or title. Strength of ideas trumps position on an org chart
        If you share our values, you should have:
        * Proven experience (2 years) with distributed systems, e.g. Mesos, Kubernetes, Spark, Hadoop, distributed databases, grid computing
        * Experience with stream processing, e.g. Kafka, Spark Streaming, Akka, Flink, etc.
        * Fluency in Java or Scala (3 years), or demonstrated mastery of another language with clear movement towards one of the JVM languages
        * Experience data modeling for large scale databases, either relational or NoSQL
        * Demonstrated ability to solve complex problems
        * Experience working with scientific datasets, or a background in the application of quantitative science to business problems
        Bonus points for:
        * Bioinformatics experience, especially large scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlation
        * Experience with ADAM or GA4GH variant schemas
        * Ability to build and maintain modern cloud architecture, e.g. AWS, Google Cloud, etc.
        * Comfortable speaking publicly on relevant work
        * Experience contributing to open source projects
        * Knowledge of data science practices, to better steer our efforts to support them through the infrastructure we create
        We encourage you to share with us any and all public contributions you have made in the form of conference presentations, community forums (e.g. Stack Overflow, GitHub, etc.), or open source projects and code samples.