        GENERAL FUNCTION:
        The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data. The person in this role creates scalable and reusable solutions for gathering, collecting, storing, processing, and serving data on both small and very large (i.e. Big Data) scales. These solutions can include on-premise and cloud-based data platforms, and solutions in any of the following domains – ETL, business intelligence, analytics, persistence (relational, NoSQL, data lakes), search, messaging, data warehousing, stream processing, and machine learning.
        As a member of the Big Data Engineering and Data Architecture team, this person will specialize in Big Data technologies and solutions, helping to build and support the company's Data Lake and Streaming Data Platforms. This team will also help to shape the strategy related to traditional database and data warehousing technologies, ETL/ELT platforms, and business intelligence tooling.
        Responsible and accountable for risk by openly exchanging ideas and opinions, elevating concerns, and personally following policies and procedures as defined. Accountable for always doing the right thing for customers and colleagues, and ensures that actions and behaviors drive a positive customer experience. While operating within the Bank's risk appetite, achieves results by consistently identifying, assessing, managing, monitoring, and reporting risks of all types.
        DUTIES & RESPONSIBILITIES:
        1. Responsible for design, development, and support of Big Data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities.
        2. Work closely with IT application teams, Enterprise Architecture, Infrastructure, Information Security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the bank.
        3. Act as a technical expert addressing problems related to system and application design, performance, integration, security, etc.
        4. Conduct research and development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics.
        5. Work with developers to build CI/CD pipelines, self-service build tools, and automated deployment processes.
        6. Evaluate software products and provide documented recommendations as needed.
        7. Provide support and troubleshooting for Big Data platforms. Must be willing to provide escalated on-call support for complicated and/or critical incidents.
        8. Participate in the planning process for hardware and software.
        9. Plan and work on internal projects as needed, including legacy system replacement, monitoring and analytics improvements, tool development, and technical documentation.
        10. Provide technical guidance and mentoring for other team members.
        11. Manage and prioritize multiple assignments.
        12. Other duties as required.
        MINIMUM KNOWLEDGE, SKILLS AND ABILITIES REQUIRED:
        1. Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience
        2. Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group.
        3. At least 8 years of experience in one or more hands-on software development roles
        4. Significant experience developing and supporting Java applications (at least 6 years)
        5. Significant experience with two or more major RDBMS products
        6. Significant experience working with and supporting Unix/Linux and Windows systems
        7. Proficient in relational database modeling concepts and techniques
        8. Strong conceptual understanding of distributed computing principles
        9. Strong knowledge of application and data security concepts, best practices, and common vulnerabilities
        10. Real-world experience with Big Data technologies is strongly preferred (e.g. Hadoop, Hive, HBase, Spark, Elas ticSearch/Solr, Kafka, etc.).
        11. Experience with any of the following is preferred, but not required – IBM BigInsights (or other major Hadoop distribution), metadata management products, commercial or open source ETL tools (esp. IBM InfoSphere Information Server / DataStage or Talend), BI and Data Science tools, messaging systems (esp. Kafka/Confluent, MQ), machine learning toolkits, data warehousing, Spring Framework, Python, Scala, R, version control systems (esp. ClearCase, Git), continuous integration/delivery, infrastructure automation and virtualization (esp. Docker, Chef, Puppet, Ansible), major cloud providers (esp. Amazon AWS and IBM BlueMix), or REST API design and development.
        12. Experience working with offshore teams is preferred, but not required.
        13. Financial industry experience is preferred, but not required.